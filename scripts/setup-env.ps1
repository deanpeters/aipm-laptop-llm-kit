# Environment Setup Script for AIPM Laptop LLM Kit - Windows
# Sets up environment variables safely

param(
    [switch]$DryRun
)

$ScriptDir = Split-Path -Parent $MyInvocation.MyCommand.Definition
$ProjectRoot = Split-Path -Parent $ScriptDir

function Write-Success {
    param($Message)
    Write-Host "✅ $Message" -ForegroundColor Green
}

function Write-Warning-Custom {
    param($Message)
    Write-Host "⚠️ $Message" -ForegroundColor Yellow
}

function Write-Log {
    param($Message)
    Write-Host $Message
}

# Create .env file if it doesn't exist
function New-EnvFile {
    $envFile = Join-Path $ProjectRoot ".env"
    $envExample = Join-Path $ProjectRoot "config\env.example"
    
    if (!(Test-Path $envFile)) {
        if (Test-Path $envExample) {
            Copy-Item $envExample $envFile
            Write-Success "Created .env file from template"
        }
        else {
            # Create basic .env file with API key patterns
            $envContent = @"
# AIPM Laptop LLM Kit Environment Variables
# Generated by installer on $(Get-Date)

# Local LLM Configuration (LM Studio)
LLM_BASE_URL=http://localhost:1234/v1
LLM_API_KEY=local-lmstudio-key
LLM_MODEL_NAME=phi-3-mini-4k-instruct

# Docker-accessible LLM endpoint (for n8n, LangFlow, etc.)
LLM_DOCKER_URL=http://host.docker.internal:1234/v1

# Ollama Configuration (alternative to LM Studio)
OLLAMA_BASE_URL=http://localhost:11434/v1
OLLAMA_API_KEY=local-ollama-key
OLLAMA_MODEL_NAME=phi4-mini:latest
OLLAMA_DOCKER_URL=http://host.docker.internal:11434/v1

# Service ports
ANYTHINGLLM_PORT=3001
N8N_PORT=5678
PRIVATEGPT_PORT=8001
LANGFLOW_PORT=7860
OLLAMA_WEBUI_PORT=8080

# Storage paths (relative to project root)
ANYTHINGLLM_STORAGE=./storage/anythingllm
N8N_STORAGE=./storage/n8n
PRIVATEGPT_STORAGE=./storage/privategpt
LANGFLOW_STORAGE=./storage/langflow
OLLAMA_WEBUI_STORAGE=./storage/ollama-webui

# Project configuration
SOV_STACK_HOME=$ProjectRoot

# Example: Uncomment and customize for specialized models
# PM_SPECIALIST_URL=http://localhost:1234/v1
# PM_SPECIALIST_KEY=local-pm-specialist-key  
# PM_SPECIALIST_MODEL=pm-assistant-v2

# Example: External API keys for hybrid workflows
# OPENAI_API_KEY=sk-your-openai-key-here
# ANTHROPIC_API_KEY=sk-ant-your-anthropic-key-here
"@
            Set-Content -Path $envFile -Value $envContent
            Write-Success "Created basic .env file"
        }
    }
    else {
        Write-Log ".env file already exists"
    }
}

# Set user environment variables
function Set-UserEnvironment {
    $envVars = @{
        "LLM_BASE_URL" = "http://localhost:1234/v1"
        "LLM_API_KEY" = "local-lmstudio-key"
        "LLM_MODEL_NAME" = "phi-3-mini-4k-instruct"
        "LLM_DOCKER_URL" = "http://host.docker.internal:1234/v1"
        "OLLAMA_BASE_URL" = "http://localhost:11434/v1"
        "OLLAMA_API_KEY" = "local-ollama-key"
        "OLLAMA_MODEL_NAME" = "phi4-mini:latest"
        "OLLAMA_DOCKER_URL" = "http://host.docker.internal:11434/v1"
        "ANYTHINGLLM_PORT" = "3001"
        "N8N_PORT" = "5678"
        "PRIVATEGPT_PORT" = "8001"
        "LANGFLOW_PORT" = "7860"
        "OLLAMA_WEBUI_PORT" = "8080"
        "ANYTHINGLLM_STORAGE" = "$ProjectRoot\storage\anythingllm"
        "N8N_STORAGE" = "$ProjectRoot\storage\n8n"
        "PRIVATEGPT_STORAGE" = "$ProjectRoot\storage\privategpt"
        "LANGFLOW_STORAGE" = "$ProjectRoot\storage\langflow"
        "OLLAMA_WEBUI_STORAGE" = "$ProjectRoot\storage\ollama-webui"
        "SOV_STACK_HOME" = $ProjectRoot
    }
    
    Write-Log "Setting user environment variables..."
    
    foreach ($var in $envVars.GetEnumerator()) {
        $existing = [Environment]::GetEnvironmentVariable($var.Key, [EnvironmentVariableTarget]::User)
        if ([string]::IsNullOrEmpty($existing)) {
            if (!$DryRun) {
                [Environment]::SetEnvironmentVariable($var.Key, $var.Value, [EnvironmentVariableTarget]::User)
                # Also set for current session
                Set-Item -Path "env:$($var.Key)" -Value $var.Value -Force
            }
            Write-Success "Set $($var.Key) = $($var.Value)"
        }
        else {
            Write-Log "$($var.Key) already set to: $existing"
        }
    }
}

# Create storage directories
function New-StorageDirectories {
    $storageBase = Join-Path $ProjectRoot "storage"
    $dirs = @(
        "anythingllm",
        "n8n", 
        "privategpt",
        "langflow",
        "ollama-webui"
    )
    
    foreach ($dir in $dirs) {
        $fullPath = Join-Path $storageBase $dir
        if (!(Test-Path $fullPath)) {
            if (!$DryRun) {
                New-Item -ItemType Directory -Path $fullPath -Force | Out-Null
            }
        }
    }
    
    Write-Success "Created storage directories"
}

# Load environment from .env file
function Import-EnvFile {
    $envFile = Join-Path $ProjectRoot ".env"
    if (Test-Path $envFile) {
        Get-Content $envFile | ForEach-Object {
            if ($_ -match '^([^#][^=]*)=(.*)$') {
                $name = $matches[1].Trim()
                $value = $matches[2].Trim()
                # Remove quotes if present
                $value = $value -replace '^["\']|["\']$', ''
                Set-Item -Path "env:$name" -Value $value -Force
            }
        }
        Write-Success "Loaded environment variables from .env"
    }
}

# Print environment summary
function Show-EnvironmentSummary {
    Write-Log ""
    Write-Log "=== Environment Summary ==="
    Write-Log "Local LLM Configuration:"
    Write-Log "  LLM_BASE_URL: $env:LLM_BASE_URL"
    Write-Log "  LLM_API_KEY: $env:LLM_API_KEY"
    Write-Log "  LLM_MODEL_NAME: $env:LLM_MODEL_NAME"
    Write-Log "  LLM_DOCKER_URL: $env:LLM_DOCKER_URL"
    Write-Log ""
    Write-Log "Service Ports:"
    Write-Log "  AnythingLLM: $env:ANYTHINGLLM_PORT"
    Write-Log "  n8n: $env:N8N_PORT"
    Write-Log "  LangFlow: $env:LANGFLOW_PORT"
    Write-Log ""
    Write-Log "Project Home: $env:SOV_STACK_HOME"
    Write-Log ""
    Write-Success "These environment variables are now available for:"
    Write-Log "  • n8n workflows (use ={{`$env.LLM_API_KEY}} syntax)"
    Write-Log "  • LangFlow components (use {LLM_MODEL_NAME} syntax)"
    Write-Log "  • VS Code integrations"
    Write-Log "  • Custom scripts and tools"
    Write-Log ""
    Write-Warning-Custom "Please restart PowerShell or open a new terminal to use these variables in other sessions"
}

# Main function
function Main {
    Write-Log "Setting up AIPM Laptop LLM Kit environment..."
    
    New-EnvFile
    Set-UserEnvironment
    New-StorageDirectories
    Import-EnvFile
    Show-EnvironmentSummary
    
    Write-Success "Environment setup complete!"
}

Main